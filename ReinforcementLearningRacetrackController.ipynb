{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTwxtLIKtd5e"
      },
      "outputs": [],
      "source": [
        "# PARAMETERS\n",
        "GROUP_ID = 'Group11'\n",
        "ALGORITHM = \"ValItr\"\n",
        "TRACK_NAME = \"/content/drive/MyDrive/tracks/W-track.txt\"\n",
        "CRASH_POS = 'STRT'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive, unneccessary if not using google colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kWqxeKjd2BH6",
        "outputId": "906a7278-b079-48b1-9bde-ed5df310fdca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Racetrack Implementation\n",
        "\n",
        "import random\n",
        "\n",
        "# Track Loading/Representation\n",
        "def load_track(file_path):\n",
        "  # PARAMETERS\n",
        "  # file_path: path to track file\n",
        "  # RETURNS\n",
        "  # rows: number of rows in track\n",
        "  # columns: number of columns in track\n",
        "  # grid: 2D list of strings, the track grid\n",
        "  # start: list of tuples, starting positions\n",
        "  # finish: list of tuples, finish positions\n",
        "  # walls: list of tuples, wall positions\n",
        "  # track: list of tuples, empty track cells\n",
        "\n",
        "  # Read file\n",
        "  with open(file_path, \"r\") as f:\n",
        "    first_line = f.readline().strip()\n",
        "    rows, columns = map(int, first_line.split(\",\"))\n",
        "\n",
        "    grid = []\n",
        "    start_positions = []\n",
        "    finish_positions = []\n",
        "    walls = []\n",
        "    track = []\n",
        "\n",
        "    for r in range(rows):\n",
        "      line = f.readline().strip()\n",
        "      row_list = list(line)\n",
        "      grid.append(row_list)\n",
        "\n",
        "      # Classify each character appropriately\n",
        "      for c, char in enumerate(row_list):\n",
        "        if char == 'S':\n",
        "          start_positions.append((r,c))\n",
        "        if char == 'F':\n",
        "          finish_positions.append((r,c))\n",
        "        if char == '#':\n",
        "          walls.append((r,c))\n",
        "        if char == '.':\n",
        "          track.append((r,c))\n",
        "\n",
        "    return {\n",
        "        \"rows\": rows,\n",
        "        \"columns\": columns,\n",
        "        \"grid\": grid,\n",
        "        \"start\": start_positions,\n",
        "        \"finish\": finish_positions,\n",
        "        \"walls\": walls,\n",
        "        \"track\": track\n",
        "    }\n",
        "\n",
        "# State Representation\n",
        "# Check if state (position and velocity) is valid\n",
        "def is_valid(position, velocity, grid):\n",
        "  # PARAMETERS\n",
        "  # position: (row, column) tuple of current position\n",
        "  # velocity: tuple of current velocity\n",
        "  # grid: 2D list of strings, the track grid\n",
        "  # RETURNS\n",
        "  # boolean: True if position and velocity are valid, false otherwise\n",
        "\n",
        "  row, column = position\n",
        "  vx, vy = velocity\n",
        "\n",
        "  rows = len(grid)\n",
        "  columns = len(grid[0])\n",
        "\n",
        "  # Verify position is inside grid\n",
        "  if row < 0 or row >= rows or column < 0 or column >= columns:\n",
        "    return False\n",
        "\n",
        "  # Verify position isn't wall\n",
        "  if grid[row][column] == '#':\n",
        "    return False\n",
        "\n",
        "  # Verify velocity is [-5,5]\n",
        "  if not (-5 <= vx <= 5) or not (-5 <= vy <= 5):\n",
        "    return False\n",
        "\n",
        "  # Position and velocity are valid\n",
        "  return True\n",
        "\n",
        "# Action Representation\n",
        "def acceleration_attempt(acceleration):\n",
        "  # PARAMETERS\n",
        "  # acceleration: tuple of intended acceleration\n",
        "  # RETURNS\n",
        "  # tuple of actual acceleration applied\n",
        "\n",
        "  ax,ay = acceleration\n",
        "\n",
        "  # 80% probability of using intended acceleration\n",
        "  if random.random() < 0.8:\n",
        "    return (ax,ay)\n",
        "  # 20% probabililty of acceleration failing\n",
        "  else:\n",
        "    return (0,0)\n",
        "\n",
        "def deterministic_update(position, velocity, acceleration):\n",
        "  # PARAMETERS\n",
        "  # position: tuple of current position on track\n",
        "  # velocity: tuple of current velocity\n",
        "  # acceleration: tuple of current acceleration\n",
        "  # RETURNS\n",
        "  # new position and new velocity tuples\n",
        "\n",
        "  x, y = position\n",
        "  vx, vy = velocity\n",
        "  ax, ay = acceleration\n",
        "  vx = max(-5, min(5, vx + ax))\n",
        "  vy = max(-5, min(5, vy + ay))\n",
        "\n",
        "  return (x + vx, y + vy), (vx, vy)\n",
        "\n",
        "# Wall Collision Detection\n",
        "def bresenham_algorithm(x0, y0, x1, y1):\n",
        "  # PARAMETERS\n",
        "  # x0, y0: starting coordinates\n",
        "  # x1, y1: ending coordinates\n",
        "  # RETURNS\n",
        "  # Every grid cell the line from (x0, y0) to (x1, y1) goes through\n",
        "\n",
        "  visited_points = []\n",
        "\n",
        "  # Horizontal and vertical distances\n",
        "  dx = abs(x1-x0)\n",
        "  dy = abs(y1-y0)\n",
        "\n",
        "  # Step directions in x (left or right) and y (up or down)\n",
        "  sx = 1 if x0 < x1 else -1\n",
        "  sy = 1 if y0 < y1 else -1\n",
        "\n",
        "  # Error term\n",
        "  error = dx - dy\n",
        "\n",
        "  # Loop start to end, one step at a time\n",
        "  while True:\n",
        "    # Add current point to path\n",
        "    visited_points.append((x0, y0))\n",
        "\n",
        "    # Stop when end point reached\n",
        "    if x0 == x1 and y0 == y1:\n",
        "      break\n",
        "\n",
        "    # Double error value for comparison\n",
        "    error2 = 2 * error\n",
        "\n",
        "    # Move horizontally if error is large\n",
        "    if error2 > -dy:\n",
        "      error -= dy\n",
        "      x0 += sx\n",
        "\n",
        "    # Move vertically if error is small\n",
        "    if error2 < dx:\n",
        "      error += dx\n",
        "      y0 += sy\n",
        "\n",
        "  return visited_points\n",
        "\n",
        "def collision(x0, y0, x1, y1, grid):\n",
        "  # PARAMETERS\n",
        "  # x0, y0: starting coordinates\n",
        "  # x1, y1: ending coordiates\n",
        "  # grid: 2D list of strings, track grid\n",
        "  # RETURNS\n",
        "  # Boolean: true if no crash and False if crash\n",
        "  # Tuple: coordinates of final position of crash position\n",
        "\n",
        "  rows = len(grid)\n",
        "  columns = len(grid[0])\n",
        "\n",
        "  # List of all cells car went through\n",
        "  path = bresenham_algorithm(x0, y0, x1, y1)\n",
        "\n",
        "  # Check each cell in path\n",
        "  for (r, c) in path:\n",
        "    # Crash if outside grid\n",
        "    if r < 0 or r >= rows or c < 0 or c >= columns:\n",
        "      return False, (r, c)\n",
        "\n",
        "    # Crash if cell is a wall (#)\n",
        "    if grid[r][c] == '#':\n",
        "      return False, (r, c)\n",
        "\n",
        "  # No collision\n",
        "  return True, (x1, y1)\n",
        "\n",
        "# Crash Handling\n",
        "# Finds nearest position on track to crash\n",
        "def NRST(grid):\n",
        "  # PARAMETERS\n",
        "  # grid: 2D list of strings, the track grid\n",
        "  # RETURNS\n",
        "  # nrst_table: dictionary maping each cell to nearest track cell\n",
        "\n",
        "  rows = len(grid)\n",
        "  columns = len(grid[0])\n",
        "  valid_cells = [(r,c) for r in range(rows) for c in range(columns) if grid[r][c] != '#']\n",
        "  nrst_table = {}\n",
        "\n",
        "  # Loop through every row and column\n",
        "  for r in range(rows):\n",
        "    for c in range(columns):\n",
        "      # Ignore walls\n",
        "      if grid[r][c] != '#':\n",
        "        nrst_table[(r,c)] = (r,c)\n",
        "        continue\n",
        "      # Use Manhattan Distance to find nearest valid cell\n",
        "      nearest = min(valid_cells, key=lambda cell: abs(cell[0]-r) + abs(cell[1]-c))\n",
        "      nrst_table[(r,c)] = nearest\n",
        "\n",
        "  return nrst_table\n",
        "\n",
        "# Takes crashed car back to start\n",
        "def STRT(start_positions):\n",
        "  # PARAMETERS\n",
        "  # start_positions: list of tuples of all starting positions\n",
        "  # RETURNS\n",
        "  # tuple of chosen start position and reset velocity\n",
        "\n",
        "  return (start_positions[0][0], start_positions[0][1], 0, 0)\n",
        "\n",
        "\n",
        "# Finish Line Detection\n",
        "def finish_line(position, finish_positions):\n",
        "  # PARAMETERS\n",
        "  # position: (row, col) tuple\n",
        "  # finish_positions: list of tuples of finish line cells\n",
        "  # RETURNS\n",
        "  # boolean: True if position crosses finish, False otherwise\n",
        "\n",
        "  return position in finish_positions\n",
        "\n",
        "# Update Velocity and Posiiton\n",
        "def update_velocity_position(position, velocity, acceleration):\n",
        "  # PARAMETERS\n",
        "  # position: (row, col) tuple\n",
        "  # velocity: (vx, vy) tuple\n",
        "  # acceleration: (ax, ay) tuple\n",
        "  # RETURNS\n",
        "  # new_position: tuple (x, y)\n",
        "  # new_velocity: tuple (vx, vy)\n",
        "\n",
        "  (x, y) = position\n",
        "  (vx, vy) = velocity\n",
        "  (ax, ay) = acceleration\n",
        "\n",
        "  ax, ay = acceleration_attempt((ax,ay))\n",
        "\n",
        "  # Update velocity (old velocity plus accleration)\n",
        "  vx = max(-5, min(5, vx + ax))\n",
        "  vy = max(-5, min(5, vy + ay))\n",
        "\n",
        "  # Update position (old position + new velocity)\n",
        "  new_x = x + vx\n",
        "  new_y = y + vy\n",
        "\n",
        "  return (new_x, new_y), (vx, vy)\n",
        "\n",
        "# Simulation Runner// NO LONGER BEING USED\n",
        "def simulate(track, actions, CRASH_POS):\n",
        "  # PARAMETERS\n",
        "  # track: output from load_track\n",
        "  # actions: list of tuples of actions\n",
        "  # CRASH_POS: STRT ot NRST, crash handling method\n",
        "  # RETURNS\n",
        "  # path: list of postions car traveled\n",
        "  # steps: number of steps taken\n",
        "  # finished boolean: True if finish reached, False otherwise\n",
        "\n",
        "  grid = track[\"grid\"]\n",
        "  start_positions = track[\"start\"]\n",
        "  finish_positions = track[\"finish\"]\n",
        "\n",
        "  # Initial state (choose random start)\n",
        "  position = STRT(start_positions)\n",
        "  velocity = (0,0)\n",
        "\n",
        "  path = [position]\n",
        "\n",
        "  for action in actions:\n",
        "    # Update velocity and position\n",
        "    new_position, new_velocity = update_velocity_position(position, velocity, action)\n",
        "\n",
        "    # Bresenham's algorithm coordinates\n",
        "    x0, y0 = position\n",
        "    x1, y1 = new_position\n",
        "\n",
        "    # Check for collision\n",
        "    no_crash, result = collision(x0, y0, x1, y1, grid)\n",
        "\n",
        "    if not no_crash:\n",
        "      # Crash\n",
        "      crash_r, crash_c = result\n",
        "\n",
        "      if CRASH_POS == 'STRT':\n",
        "        position = STRT(start_positions)\n",
        "\n",
        "      elif CRASH_POS == 'NRST':\n",
        "        nearest = NRST(crash_r, crash_c, grid)\n",
        "        position = nearest if nearest is not None else STRT(start_positions)\n",
        "\n",
        "      # Reset velocity\n",
        "      velocity = (0,0)\n",
        "\n",
        "      path.append(position)\n",
        "      continue\n",
        "\n",
        "    # No crash\n",
        "    position = new_position\n",
        "    velocity = new_velocity\n",
        "    path.append(position)\n",
        "\n",
        "    if finish_line(position, finish_positions):\n",
        "      return path,len(path), True\n",
        "\n",
        "  return path, len(path), False\n",
        "\n",
        "def racetrack_MDP(grid, start_positions, finish_positions):\n",
        "  # PARAMETERS\n",
        "  # grid: 2D list of strings, the track grid\n",
        "  # start_positions: list of tuples for all valid start positions\n",
        "  # finish_positions: list of tuples for all finish line positions\n",
        "  # RETURNS\n",
        "  # states: list of all possible MDP states\n",
        "  # actions: list of all possible accelerations\n",
        "\n",
        "  maximum_rows = len(grid)\n",
        "  maximum_columns = len(grid[0])\n",
        "\n",
        "  # Velocities [-5,5]\n",
        "  velocity_range = range(-5,6)\n",
        "\n",
        "  actions = [(ax,ay) for ax in (-1, 0, 1) for ay in (-1,0,1)]\n",
        "\n",
        "  states = []\n",
        "\n",
        "  for r in range(maximum_rows):\n",
        "    for c in range(maximum_columns):\n",
        "      if grid[r][c] == '#':\n",
        "        continue\n",
        "      for vx in velocity_range:\n",
        "        for vy in velocity_range:\n",
        "          states.append((r,c,vx,vy))\n",
        "\n",
        "  return states, actions\n"
      ],
      "metadata": {
        "id": "forsbLDlwFP4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new simulation function to take in a policy for a track and crash policy and simulate it with the 20% chance of failure\n",
        "# and get the resulting path\n",
        "def run_simulation(policy, track, CRASH_POS, nrst_table):\n",
        "    # inputs:\n",
        "    # policy: policy dictionary mapping every state to an action\n",
        "    # track: loaded track object\n",
        "    # CRASH_POS: crash policy for the run\n",
        "    # returns:\n",
        "    # steps: number of steps taken in the simulation for it to finsih\n",
        "    # path: the path taken by the agent (point to point) during the simulation\n",
        "    # finished: boolean, whether or not the agent crossed the finish line\n",
        "    # initialize the starting posiiton on the track and velocity\n",
        "    start_node = STRT(track[\"start\"])\n",
        "    position_xy = (start_node[0], start_node[1])\n",
        "    velocity = (start_node[2], start_node[3])\n",
        "    # initlialize return values to be kept track of\n",
        "    path = [start_node]\n",
        "    steps = 0\n",
        "    finished = False\n",
        "    # maximum number of simulation steps allowed to prevent infinite looping if policy is bad\n",
        "    MAX_SIM_STEPS = 1000000\n",
        "\n",
        "    for _ in range(MAX_SIM_STEPS):\n",
        "      # increment steps and change state based on previous action\n",
        "        steps += 1\n",
        "        state = (position_xy[0], position_xy[1], velocity[0], velocity[1])\n",
        "\n",
        "        # look up next appropriate action for the current state\n",
        "        action = policy.get(state, (0, 0))\n",
        "\n",
        "        # try and do action and retrieve the acceleration (if the action was done or not)\n",
        "        actual_accel = acceleration_attempt(action)\n",
        "        curr_vx, curr_vy = velocity # label current velocity so the new one can be found\n",
        "        vx = max(-5, min(5, curr_vx + actual_accel[0])) # caculate new velocity based on action\n",
        "        vy = max(-5, min(5, curr_vy + actual_accel[1]))\n",
        "        new_position_xy = (position_xy[0] + vx, position_xy[1] + vy) # calculate new position based on new velocity\n",
        "        new_velocity = (vx, vy) # make new velocity a tuple\n",
        "\n",
        "        # check to see if the action/velocity/position caused a crash\n",
        "        no_crash, (crash_r, crash_c) = collision(\n",
        "            position_xy[0], position_xy[1],\n",
        "            new_position_xy[0], new_position_xy[1],\n",
        "            track[\"grid\"]\n",
        "        )\n",
        "\n",
        "        if not no_crash: # if there was a crash, update position based on crash policy\n",
        "            if CRASH_POS == 'STRT': # if STRT crash policy, reset car posiiton to the start and reset velcotiy\n",
        "                s_node = STRT(track[\"start\"])\n",
        "                position_xy = (s_node[0], s_node[1])\n",
        "                velocity = (0,0)\n",
        "            else: # if NRST policy, reset car position to nearest spot and zero out velcoity\n",
        "                nearest = nrst_table.get((crash_r, crash_c), STRT(track[\"start\"]))\n",
        "                position_xy = (nearest[0], nearest[1])\n",
        "                velocity = (0, 0)\n",
        "        else:\n",
        "            position_xy = new_position_xy # if no crash proceed as normal\n",
        "            velocity = new_velocity\n",
        "        # add wherever the car wen to the path\n",
        "        path.append((position_xy[0], position_xy[1], velocity[0], velocity[1]))\n",
        "        # check if the car made it past the finish line, if yes, break\n",
        "        if finish_line(position_xy, track[\"finish\"]):\n",
        "            finished = True\n",
        "            break\n",
        "\n",
        "    return path, steps, finished"
      ],
      "metadata": {
        "id": "FzHG2nARo2RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Value Iteration\n",
        "\n",
        "def value_iteration(track, states, actions, gamma, epsilon, CRASH_POS):\n",
        "  # PARAMETERS\n",
        "  # track: loaded track object\n",
        "  # states: list of all states (position and velocity)\n",
        "  # actions: list of all possible actions\n",
        "  # gamma: discount factor\n",
        "  # epsilon: convergence threshold\n",
        "  # CRASH_POS: crash policy\n",
        "  # RETURNS\n",
        "  # policy: dictionary mapping states to best actions\n",
        "  # state_values: dictionary mapping states to values\n",
        "  # t: count of iterations\n",
        "\n",
        "  # Initialize state values (how good a state is)\n",
        "  state_values = {s: 0 for s in states}\n",
        "  # Policy is initally unknown\n",
        "  policy = {s: None for s in states}\n",
        "\n",
        "  nrst_table = NRST(track[\"grid\"])\n",
        "\n",
        "  t = 0 # t tracks number of iterations\n",
        "  # Repeat until convergence\n",
        "  while True:\n",
        "    t += 1\n",
        "    # Track maximum change in state values this iteration\n",
        "    delta = 0\n",
        "\n",
        "    # Loop each state\n",
        "    for s in states:\n",
        "      old_value = state_values[s]\n",
        "      # Dictionary to hold Q-values\n",
        "      q_values = {}\n",
        "\n",
        "      # Loop each action and calculate Q-value\n",
        "      for a in actions:\n",
        "        q_values[a] = reward(s,a, track) + gamma * expected_future_value(s, a, state_values, track, CRASH_POS, nrst_table)\n",
        "\n",
        "      # Pick best action according to state values\n",
        "      best_action = max(q_values, key=q_values.get)\n",
        "      # Update policy for this state\n",
        "      policy[s] = best_action\n",
        "\n",
        "      # Update state value with maximum Q-value\n",
        "      state_values[s] = q_values[best_action]\n",
        "\n",
        "      # Largest change across al states\n",
        "      delta = max(delta, abs(old_value - state_values[s]))\n",
        "\n",
        "    # Check for convergence (stop iterating when max change is smaller than epsilon)\n",
        "    if delta < epsilon:\n",
        "      break\n",
        "\n",
        "  # Return final plicy and state values\n",
        "  return policy, state_values, t\n",
        "\n",
        "def reward(state, action, track):\n",
        "  # PARAMETERS\n",
        "  # state: tuple of current position and velocity\n",
        "  # action: tuple of acceleration\n",
        "  # track: dictionary of grid and finish cells\n",
        "  # RETURNS\n",
        "  # FILL IN\n",
        "\n",
        "  r, c, vx, vy = state\n",
        "  grid = track[\"grid\"]\n",
        "  finish_positions = track[\"finish\"]\n",
        "\n",
        "  # Update position based on action\n",
        "  new_vx = max(-5, min(5, vx + action[0]))\n",
        "  new_vy = max(-5, min(5, vy + action[1]))\n",
        "  new_r = r + new_vx\n",
        "  new_c = c + new_vy\n",
        "\n",
        "  # Check if the new position crosses the finish line\n",
        "  if (new_r, new_c) in finish_positions:\n",
        "    return 0\n",
        "\n",
        "  # Every move costs 1\n",
        "  return -1\n",
        "\n",
        "def expected_future_value(state, action, state_values, track, CRASH_POS, nrst_table):\n",
        "  # PARAMETERS\n",
        "  # state: current position and velocity\n",
        "  # action: tuple of acceleration\n",
        "  # state_values: dictionary mapping state to value\n",
        "  # track: dictionary of grid and start positions\n",
        "  # CRASH_POS: string specifying crash response\n",
        "  # nrst_table: dictionary mapping each crash to nearest track cell\n",
        "  # RETURNS\n",
        "  # expected_value: expected future value of taking action\n",
        "\n",
        "  r, c, vx, vy = state\n",
        "  grid = track[\"grid\"]\n",
        "  start_positions = track[\"start\"]\n",
        "\n",
        "  expected_value = 0\n",
        "\n",
        "  # Acceleration succeeds (80% chance)\n",
        "  new_position, new_velocity = deterministic_update((r,c), (vx,vy),action)\n",
        "  x0, y0 = r, c\n",
        "  x1, y1 = new_position\n",
        "\n",
        "  no_crash, (crash_r, crash_c) = collision(x0, y0, x1, y1, grid)\n",
        "\n",
        "  if not no_crash:\n",
        "    if CRASH_POS == 'STRT':\n",
        "      start = STRT(start_positions)\n",
        "      new_state = (start[0], start[1], 0,0)\n",
        "    else:\n",
        "      nearest = nrst_table.get((crash_r, crash_c), STRT(start_positions))\n",
        "      new_state = (nearest[0], nearest[1], 0,0)\n",
        "\n",
        "  else:\n",
        "    new_state = (new_position[0], new_position[1], new_velocity[0], new_velocity[1])\n",
        "\n",
        "  expected_value += 0.8 * state_values.get(new_state, 0)\n",
        "\n",
        "  # Acceleration fails (20% chance)\n",
        "  # Velocity doesn't change\n",
        "  fail_position = (r + vx, c + vy)\n",
        "  no_crash, (crash_r, crash_c) = collision(r, c, fail_position[0], fail_position[1], grid)\n",
        "\n",
        "  if not no_crash:\n",
        "    if CRASH_POS == 'STRT':\n",
        "      start = STRT(start_positions)\n",
        "      fail_state = (start[0], start[1], 0,0)\n",
        "    else:\n",
        "      nearest = nrst_table.get((crash_r, crash_c), STRT(start_positions))\n",
        "      fail_state = (nearest[0], nearest[1], 0,0)\n",
        "\n",
        "  else:\n",
        "    fail_state = (fail_position[0], fail_position[1], vx, vy)\n",
        "\n",
        "  expected_value += 0.2 * state_values.get(fail_state, 0)\n",
        "\n",
        "  return expected_value"
      ],
      "metadata": {
        "id": "Gd-xS_1ewSYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# execute a step\n",
        "import random\n",
        "\n",
        "def step(state, action, track, CRASH_POS, nrst_table):\n",
        "  # PARAMETERS\n",
        "  # state: current\n",
        "  #extract elements from state\n",
        "  r, c, vx, vy = state\n",
        "  grid = track[\"grid\"]\n",
        "  start_positions = track[\"start\"]\n",
        "  finish_positions = track[\"finish\"]\n",
        "  # determine reward/penalty: each step is negative 1\n",
        "  reward = -1\n",
        "  position = (r,c)\n",
        "  velocity = (vx,vy)\n",
        "  finished = False\n",
        "\n",
        "  # Update position/velocity based on action\n",
        "  new_position, new_velocity = update_velocity_position(position, velocity, action)\n",
        "\n",
        "  # colision detection'\n",
        "  x0, y0 = position\n",
        "  x1, y1 = new_position\n",
        "\n",
        "  no_crash, result = collision(x0, y0, x1, y1, grid)\n",
        "  if not no_crash:\n",
        "    # there was a crash\n",
        "    crash_r, crash_c = result\n",
        "    if CRASH_POS == 'STRT':\n",
        "      # reset to start\n",
        "      start = STRT(start_positions)\n",
        "      next_state = (start[0], start[1], 0,0)\n",
        "    elif CRASH_POS == 'NRST':\n",
        "      # reset to nearest spot on track\n",
        "      nearest = nrst_table.get((crash_r, crash_c), STRT(start_positions))\n",
        "      next_state = (nearest[0], nearest[1], 0,0)\n",
        "  else:\n",
        "    # no crash\n",
        "    # check if across finish\n",
        "    if finish_line(new_position, finish_positions):\n",
        "      reward = 0\n",
        "      finished = True\n",
        "      next_state = None\n",
        "    else:\n",
        "      # still racing\n",
        "      next_state = (new_position[0], new_position[1], new_velocity[0], new_velocity[1])\n",
        "  return next_state, reward, finished\n"
      ],
      "metadata": {
        "id": "lqruDyC5wSQJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# q learning implementation\n",
        "def q_learning(track, max_episodes, gamma, alpha_start, epsilon_start, CRASH_POS, initial_Q=None):\n",
        "  # input\n",
        "  # track: loaded track object\n",
        "  # max_ episodes: max number of episodes allowed to be run\n",
        "  # gamma: discount factor, how much the agent cares about future reward compared to immediate\n",
        "  #alpha: learning rate, how much new info is pursued over what is already known (focused on exploitation)\n",
        "  # epsilon_start: how much the agent explores vs uses what it already knows, will decay\n",
        "  # CRASH_POS: crash policy\n",
        "  # initial Q: passed in Q table if it exists, can be none\n",
        "\n",
        "  # initlialize MDP and NRST table, build the universe\n",
        "  states, actions = racetrack_MDP(track[\"grid\"], track[\"start\"], track[\"finish\"])\n",
        "  nrst_table = NRST(track[\"grid\"]) # look up table for nearest square for NRST policy\n",
        "  # initialize Q\n",
        "  Q = { (s, a): 0.0 for s in states for a in actions }\n",
        "  # create a seperate training limit for the traing where it can explore more\n",
        "  TRAINING_STEP_LIMIT = 7000\n",
        "  # establish epsilon range for the decay process\n",
        "  curr_epsilon = epsilon_start\n",
        "  min_epsilon = 0.01\n",
        "  decay = (min_epsilon / curr_epsilon) ** (1 / (max_episodes * 0.8)) if curr_epsilon > min_epsilon else 1.0\n",
        "  # establish alpha decay\n",
        "  alpha = alpha_start\n",
        "  min_alpha = 0.01\n",
        "  alpha_decay = (min_alpha / alpha) ** (1 / (max_episodes * 0.8))\n",
        "\n",
        "\n",
        "  # DO training iterations/episodes\n",
        "  for i in range(max_episodes):\n",
        "      # check if a succesful path is found and stop iterations early if so\n",
        "      if i > 0 and i % 2000 == 0:\n",
        "          # convert the current Q to a policy\n",
        "          temp_policy = {}\n",
        "          for s in states: # for each state find the best valued action (least negative)\n",
        "              best_val = -float('inf')\n",
        "              best_a = (0,0)\n",
        "              for a in actions: # find the best action and add that action to the temp policy\n",
        "                  val = Q.get((s, a), 0.0)\n",
        "                  if val > best_val:\n",
        "                      best_val = val\n",
        "                      best_a = a\n",
        "              temp_policy[s] = best_a\n",
        "\n",
        "          # test/ simulate this policy and if it finishes then just return this Q table\n",
        "          _, _, test_fin = run_simulation(temp_policy, track, CRASH_POS, nrst_table)\n",
        "\n",
        "          if test_fin: # if the test finished return the Q table\n",
        "              return Q\n",
        "\n",
        "      # if policy doesn't work, continue on testing iterations (reset things)\n",
        "      start_node = STRT(track[\"start\"])\n",
        "      curr_state = start_node\n",
        "      done = False\n",
        "      steps = 0\n",
        "\n",
        "      while not done: # while we haven't reach finish line\n",
        "          if steps >= TRAINING_STEP_LIMIT: # stop at step limit if reached\n",
        "              break\n",
        "          steps += 1\n",
        "          # determine, given the value of epsilon if a random action or known action will be taken\n",
        "          if random.random() < curr_epsilon:\n",
        "              action = random.choice(actions) # choose random action\n",
        "          else:\n",
        "              # choose best know action, if tie randomly choose ONE of the best\n",
        "              best_val = -float('inf')\n",
        "              best_actions = []\n",
        "              for a in actions:\n",
        "                  val = Q.get((curr_state, a), 0.0) # get value for each action\n",
        "                  if val > best_val:\n",
        "                      best_val = val # keep track of best val\n",
        "                      best_actions = [a]\n",
        "                  elif val == best_val:\n",
        "                      best_actions.append(a) # if tie add to list\n",
        "              action = random.choice(best_actions) # break the tie if needed\n",
        "\n",
        "          # with action chosen, take/simulate the next step for the car given the current state and\n",
        "          # get the next state, reward, and if that action finished the track\n",
        "          next_state, reward, done = step(curr_state, action, track, CRASH_POS, nrst_table)\n",
        "\n",
        "          # if that action didn't finish the track, check all q values in q to see if a new max q has been found\n",
        "          max_q_next = 0.0\n",
        "          if not done:\n",
        "              max_q_next = -float('inf')\n",
        "              for a in actions:\n",
        "                  val = Q.get((next_state, a), 0.0)\n",
        "                  if val > max_q_next: max_q_next = val # if found update it\n",
        "              if max_q_next == -float('inf'): max_q_next = 0.0 # if not found keep it at 0\n",
        "          # find the current q\n",
        "          curr_q = Q.get((curr_state, action), 0.0)\n",
        "          # set the q for the current state, action pair via the following calculate\n",
        "          Q[(curr_state, action)] = curr_q + alpha * (reward + gamma * max_q_next - curr_q)\n",
        "          # move the next state\n",
        "          curr_state = next_state\n",
        "      # decay epsilon unless it has gone below the minimum epsilon required, we still want some chance of exloration to always be there\n",
        "      if curr_epsilon > min_epsilon:\n",
        "          curr_epsilon *= decay\n",
        "      if alpha > min_alpha:\n",
        "        alpha *= alpha_decay\n",
        "\n",
        "  return Q"
      ],
      "metadata": {
        "id": "QBHBBBYjplOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OUTPUT/EXPORT\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import ListedColormap\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def visualize_race(track, path, title, filename):\n",
        "    # creates a png of the track and path taken\n",
        "    # INPUTS\n",
        "    # track: loaded track data structure\n",
        "    # path: path taken by the algorithm for the specific track\n",
        "    # title: title of the algorithm used on what track with what policy\n",
        "    # filename: name is save the png to\n",
        "    #OUTPUTS\n",
        "    # saves png to the current directory\n",
        "    grid = track['grid']\n",
        "    rows = track['rows']\n",
        "    cols = track['columns']\n",
        "\n",
        "    # create grid\n",
        "    # key:\n",
        "    # 0: wall (black), 1: track (white), 2: start (red), 3: finish (green)\n",
        "    vis_grid = np.zeros((rows, cols))\n",
        "\n",
        "    # assign each cell a color based on its value of the input track that signals wall, track, start, finish\n",
        "    for r in range(rows):\n",
        "        for c in range(cols):\n",
        "            char = grid[r][c]\n",
        "            if char == '#':\n",
        "                vis_grid[r, c] = 0\n",
        "            elif char == '.':\n",
        "                vis_grid[r, c] = 1\n",
        "            elif char == 'S':\n",
        "                vis_grid[r, c] = 2\n",
        "            elif char == 'F':\n",
        "                vis_grid[r, c] = 3\n",
        "\n",
        "    # define color map: black(0), white(1), Red(2), Green(3)\n",
        "    cmap = ListedColormap(['black', 'white', 'green', 'red']) # using light red/green for visibility\n",
        "\n",
        "    # create the plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 10))\n",
        "    ax.imshow(vis_grid, cmap=cmap, origin='upper')\n",
        "\n",
        "    # extract path coordinates\n",
        "    path_rows = [step[0] for step in path]\n",
        "    path_cols = [step[1] for step in path]\n",
        "\n",
        "    # plot the path in matplotlib\n",
        "    ax.plot(path_cols, path_rows, color='blue', linewidth=2, marker='.', markersize=5, label='Agent Path')\n",
        "\n",
        "    # mark start and end\n",
        "    ax.plot(path_cols[0], path_rows[0], 'rx', markersize=10, markeredgewidth=2, label='Start')\n",
        "    ax.plot(path_cols[-1], path_rows[-1], 'gx', markersize=10, markeredgewidth=2, label='End')\n",
        "\n",
        "    #format\n",
        "    ax.set_title(title)\n",
        "    ax.set_xlabel(\"Column (x)\")\n",
        "    ax.set_ylabel(\"Row (y)\")\n",
        "    ax.legend()\n",
        "    ax.grid(False)\n",
        "\n",
        "    # save image\n",
        "    plt.savefig(filename)\n",
        "    print(f\"Figure saved to {filename}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "4qI1Mp1FK-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SARSA\n",
        "def choose_action(state, Q, actions, epsilon):\n",
        "  # choose an actiong using greedy-epsilon strategy\n",
        "  if random.random()< epsilon: # based on chance of epsilon max decision to explore or exploit\n",
        "    return random.choice(actions)\n",
        "  else:\n",
        "    best_actions = []\n",
        "    best_value = float('-inf')\n",
        "    for a in actions:\n",
        "      q_value = Q.get((state, a), 0.0) # extract q value\n",
        "      if q_value > best_value:# if new val is better, update\n",
        "        best_value = q_value\n",
        "        best_actions = [a]\n",
        "      elif q_value == best_value: # if tie, append the action\n",
        "        best_actions.append(a)\n",
        "    return random.choice(best_actions) # deal with tie breaking by picking at random one of best actions\n",
        "\n",
        "def sarsa(track, num_episodes, alpha_start, gamma, epsilon, CRASH_POS, initial_Q=None):\n",
        "# inputs\n",
        "# track: output from load_track\n",
        "# num_episdoes: num of training iterations\n",
        "# alpha: learning rate\n",
        "# gammma: discount factor\n",
        "# epsilon: exploration rate\n",
        "# CRASH_POS: crash policy\n",
        "# outputs:\n",
        "# policy dictionary matching each state to best actions\n",
        "# Q-table\n",
        "  states, actions = racetrack_MDP(track[\"grid\"], track[\"start\"], track[\"finish\"])\n",
        "  nrst_table = NRST(track[\"grid\"])\n",
        "\n",
        "  # if q-table isn't passed in\n",
        "  if initial_Q is None:\n",
        "    Q = {}\n",
        "    for s in states:\n",
        "      for a in actions:\n",
        "        Q[(s,a)] = 0.0\n",
        "  else: # if it is passed in make a copy\n",
        "    Q = initial_Q.copy()\n",
        "  MAX_STEPS_PER_EPISODE = 1000\n",
        "\n",
        "  # establish epsilon decay situation\n",
        "  current_epsilon = 1 if initial_Q is None else epsilon\n",
        "  min_epsilon = 0.01\n",
        "  decay_rate = ((min_epsilon / current_epsilon) ** (num_episodes*0.8))\n",
        "  # alpha decay\n",
        "  alpha = alpha_start\n",
        "  min_alpha = 0.01\n",
        "  alpha_decay = (min_alpha / alpha) ** (1 / (num_episodes * 0.8))\n",
        "\n",
        "  for i in range (num_episodes): # run training iterations\n",
        "    # initialize\n",
        "    start_state = STRT(track[\"start\"])\n",
        "    current_state = start_state\n",
        "    done = False\n",
        "    steps = 0\n",
        "\n",
        "    #choose action from state based of policy in q\n",
        "    current_action = choose_action(current_state, Q, actions, current_epsilon)\n",
        "\n",
        "    while not done:\n",
        "      if steps >= MAX_STEPS_PER_EPISODE:\n",
        "        break\n",
        "      steps += 1\n",
        "      # take the action and observe the resulting reward, next state and if its done\n",
        "      next_state, reward, done = step(current_state, current_action, track, CRASH_POS, nrst_table)\n",
        "      # determine target value\n",
        "      if done:\n",
        "        target = reward\n",
        "      else: # if not done, choose another action\n",
        "        next_action = choose_action(next_state, Q, actions, current_epsilon)\n",
        "        # update target\n",
        "        target = reward + gamma * Q.get((next_state, next_action), 0.0)\n",
        "\n",
        "    # update q for each state and actions\n",
        "      current_q = Q.get((current_state, current_action), 0.0)\n",
        "      Q[(current_state, current_action)] = current_q + alpha * (target - current_q)\n",
        "      # move to next state\n",
        "      current_state = next_state\n",
        "      if not done: # move to next action if not done\n",
        "        current_action = next_action\n",
        "    # update epsilon\n",
        "    current_epsilon = max(min_epsilon, current_epsilon * decay_rate)\n",
        "    # update alpha\n",
        "    alpha = max(min_alpha, alpha * alpha_decay)\n",
        "\n",
        "  # generate final policy after training is done\n",
        "  policy = {}\n",
        "  # for each state select the best action to take and add it to the policy\n",
        "  for s in states:\n",
        "    best_q = float('-inf')\n",
        "    best_action = (0,0)\n",
        "    for a in actions:\n",
        "      q_value = Q.get((s, a), 0.0)\n",
        "      if q_value > best_q:\n",
        "        best_q = q_value\n",
        "        best_action = a\n",
        "    policy[s] = best_action\n",
        "  return policy, Q\n"
      ],
      "metadata": {
        "id": "HU56uGpzwSAB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert Q- table to policy\n",
        "def q_to_policy(Q, track):\n",
        "  # Q: q-table to be passed in\n",
        "  # track: track object being used\n",
        "  # returns: state action dictionary\n",
        "    states, actions = racetrack_MDP(track[\"grid\"], track[\"start\"], track[\"finish\"])\n",
        "    # get states and actions from environment\n",
        "    policy = {} #initialize policy\n",
        "    for s in states: # for each state find the best action that has the best q\n",
        "        best_q = -float('inf')\n",
        "        best_a = (0,0)\n",
        "        for a in actions: # find the best action\n",
        "            val = Q.get((s, a), 0.0)\n",
        "            if val > best_q:\n",
        "                best_q = val\n",
        "                best_a = a\n",
        "        policy[s] = best_a # update policy to include the best action for that state\n",
        "    return policy\n"
      ],
      "metadata": {
        "id": "5_wFOTqvJznt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TO EXECUTE ALL ALGORITHMS BASED ON HYPERPARAMETERS-- main execution block\n",
        "\n",
        "#load track\n",
        "track_obj = load_track(TRACK_NAME)\n",
        "track_filename = os.path.basename(TRACK_NAME).split('.')[0]\n",
        "# load nrst lookup table\n",
        "nrst_table = NRST(track_obj[\"grid\"])\n",
        "\n",
        "# VALUE ITERATION\n",
        "if ALGORITHM == 'ValItr':\n",
        "    states, actions = racetrack_MDP(track_obj[\"grid\"], track_obj[\"start\"], track_obj[\"finish\"])\n",
        "\n",
        "    #run val iteration algorith, return policy\n",
        "    policy_vi, values_vi, iters = value_iteration(track_obj, states, actions, 0.99, 0.01, CRASH_POS)\n",
        "\n",
        "    # simulate policy, get the path, steps and if it finished\n",
        "    path, steps, finished = run_simulation(policy_vi, track_obj, CRASH_POS, nrst_table)\n",
        "\n",
        "    # check if it finished\n",
        "    if finished:\n",
        "          success_label = \"Success\"\n",
        "    else:\n",
        "          success_label = \"Failure\"\n",
        "    # create image and path visualization and save it\n",
        "    img_name = f\"{GROUP_ID}_{ALGORITHM}_{track_filename}_{CRASH_POS}.png\"\n",
        "    visualize_race(track_obj, path, f\"{ALGORITHM} {track_filename} {CRASH_POS}: {success_label}, Steps: {steps}\", img_name)\n",
        "\n",
        "#Q LEARNING\n",
        "elif ALGORITHM == 'QLrng':\n",
        "    # run multiple iterations of q learning (up to 10) until a path is found\n",
        "    success_found = False\n",
        "\n",
        "    for i in range(1, 11):\n",
        "      final_Q = q_learning(track_obj, 200000, 0.99, 0.7, 1.0, 'STRT')\n",
        "      # convert the final Q to a policy\n",
        "      final_policy = q_to_policy(final_Q, track_obj)\n",
        "      # run a simulation of this policy to get the path, num of steps and if it finished\n",
        "      path, steps, finished = run_simulation(final_policy, track_obj, CRASH_POS, nrst_table)\n",
        "\n",
        "      # if success then save the image showing the path/create the image, if failure, indicate it\n",
        "      if finished:\n",
        "          success_label = \"Success\"\n",
        "          break\n",
        "      else:\n",
        "           success_label = \"Failure\"\n",
        "    # create image showing path and save it\n",
        "    img_name = f\"{GROUP_ID}_{ALGORITHM}_{track_filename}_{CRASH_POS}.png\"\n",
        "    visualize_race(track_obj, path, f\"{ALGORITHM} {track_filename} {CRASH_POS}: {success_label}, Steps: {steps}\", img_name)\n",
        "\n",
        "#SARSA\n",
        "elif ALGORITHM == 'SARSA':\n",
        "    # initialize success tracker\n",
        "    success_found = False\n",
        "    # give the agent 10 tries to find a path\n",
        "    for i in range(1, 11):\n",
        "      # run sarasa\n",
        "      final_policy, Q_final = sarsa(track_obj, 20000, 0.1, 0.99, 0.05, 'STRT')\n",
        "      # simulate the final policy and see what happens\n",
        "      path, steps, finished = run_simulation(final_policy, track_obj, CRASH_POS, nrst_table)\n",
        "      #check if it was successful\n",
        "      if finished:\n",
        "          success_label = \"Success\"\n",
        "          break\n",
        "      else:\n",
        "          success_label = \"Failure\"\n",
        "         # generate image\n",
        "    img_name = f\"{GROUP_ID}_{ALGORITHM}_{track_filename}_{CRASH_POS}.png\"\n",
        "    visualize_race(track_obj, path, f\"{ALGORITHM} {track_filename} {CRASH_POS}: {success_label}, Steps: {steps}\", img_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "lRL-Ewazp2jt",
        "outputId": "32acc923-2a59-498b-8db0-c06581a75673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Value Iteration...\n",
            "Figure saved to Group11_ValItr_W-track_STRT.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}